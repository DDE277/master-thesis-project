{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ecd9d6-574f-4512-a163-a01ce4615d85",
   "metadata": {},
   "source": [
    "# Creating synthetic cfDNA datasets across simulated sequencing coverage levels for down-sampling experiment\n",
    "- Loads cell-type-specific reference accessibility profiles and synthetic cell composition combinations\n",
    "- Simulates various sequencing depths (e.g., 245x to 0.1x) by scaling down the accessibility values\n",
    "- Applies a function to generate coverage-reduced versions of the ATAC-seq reference matrix by dividing and rounding counts\n",
    "- Multiplies reduced reference profiles with synthetic compositions to simulate mixed cfDNA profiles at each coverage level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34913406-a6b7-4765-8cd5-81707e215d12",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52868e4-068e-420e-80fd-8a0df97a6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8d807-3d61-44c9-af7a-134e8cae77ce",
   "metadata": {},
   "source": [
    "## Load the reference profile matrix, variance data and syn combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b37871-5fde-4934-a99d-88684eabe323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "atac_path = \"/mnt/DATA3/daniel/project/03_synthetic_samples/data/reference_marker_counts_scaled.csv\"\n",
    "\n",
    "syn_combo_path = \"/mnt/DATA3/daniel/project/03_synthetic_samples/data/combinations_syn_samples.csv\"\n",
    "\n",
    "# Load datasets\n",
    "ATAC_marker_counts_df = pd.read_csv(atac_path)\n",
    "syn_combo_df = pd.read_csv(syn_combo_path, sep=';')\n",
    "syn_combo_df.columns = syn_combo_df.columns.str.strip()\n",
    "\n",
    "# Ensure proper indexing\n",
    "if \"peak_id\" in ATAC_marker_counts_df.columns:\n",
    "    ATAC_marker_counts_df.set_index(\"peak_id\", inplace=True)\n",
    "\n",
    "# Quick check\n",
    "print(ATAC_marker_counts_df.head())\n",
    "print(syn_combo_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57142ab-e88f-4a0d-bc68-4d23ba899313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions\n",
    "print(ATAC_marker_counts_df.shape)\n",
    "print(syn_combo_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c884fb5-b10a-4e2e-9fef-eb88bebdda85",
   "metadata": {},
   "source": [
    "## Coverage reduction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a62734-b432-42e7-9aa3-1dc6b0f0ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_coverage(df: pd.DataFrame, divisor: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reduce coverage by dividing all values in the dataframe by a divisor,\n",
    "    then round to integers.\n",
    "    \"\"\"\n",
    "    # Scale to a lower mean\n",
    "    scaled_df = df / divisor\n",
    "    \n",
    "    # Round to nearest integer\n",
    "    rounded_df = scaled_df.round().astype(int)\n",
    "    \n",
    "    return rounded_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595742ff-b199-4a65-aaea-e416be80f696",
   "metadata": {},
   "source": [
    "## Define the coverage levels for reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dadc32-b19b-410c-99f1-c32a99116260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coverage levels for reduction\n",
    "coverage_levels = {\n",
    "    \"245x\": 1.15,   \n",
    "    \"80x\": 3.53,\n",
    "    \"30x\": 9.42,\n",
    "    \"9x\": 31.41,    \n",
    "    \"3x\": 94.24,\n",
    "    \"1x\": 282.71,\n",
    "    \"0.3x\": 942.36,\n",
    "    \"0.1x\": 2827.08\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ceea4-f4b6-4980-979a-99a0c067371f",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b6818-8e62-4446-8409-aa39b1c0f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coverage reduction to ATAC-seq data for all levels\n",
    "reduced_coverage_dfs = {\n",
    "    cov_label: reduce_coverage(ATAC_marker_counts_df, val_div) \n",
    "    for cov_label, val_div in coverage_levels.items()\n",
    "}\n",
    "\n",
    "# Print an example output\n",
    "print(\"Example: ATAC reduced to 0.1x coverage\")\n",
    "print(reduced_coverage_dfs[\"0.1x\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9b974-2398-428c-a4ca-52dab34fc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduced_coverage_dfs[\"1x\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99454ab0-99f8-4278-a97a-b61ad69b2325",
   "metadata": {},
   "source": [
    "# Function for synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dc06b-56e7-4ebe-98ef-6c907ffe78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_reference_with_combinations(reference_df, combo_df):\n",
    "    \"\"\"\n",
    "    Multiplies the fractions in the combo_df with the accessibility scores in reference_df\n",
    "    for each corresponding cell type.\n",
    "    \n",
    "    Args:\n",
    "        reference_df (pd.DataFrame): Reference matrix with peaks and cell types.\n",
    "        combo_df (pd.DataFrame): Synthetic combinations with proportions for each cell type.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A new dataframe with the multiplied values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure \"peak_id\" is the index\n",
    "    if reference_df.index.name != \"peak_id\":\n",
    "        reference_df = reference_df.set_index(\"peak_id\")  \n",
    "\n",
    "    # Set the first column (combo names) as index for synthetic combinations\n",
    "    combo_matrix = combo_df.set_index(combo_df.columns[0])\n",
    "\n",
    "    # Ensure both have matching cell type column names\n",
    "    common_cell_types = reference_df.columns.intersection(combo_matrix.columns)\n",
    "\n",
    "    # Subset to only the common cell types\n",
    "    reference_matrix = reference_df[common_cell_types]\n",
    "    combo_matrix = combo_matrix[common_cell_types]\n",
    "\n",
    "    # Perform element-wise multiplication for each combo separately\n",
    "    synthetic_results = {\n",
    "        f\"{combo}\": reference_matrix.multiply(combo_matrix.loc[combo], axis=1)\n",
    "        for combo in combo_matrix.index\n",
    "    }\n",
    "\n",
    "    # Concatenate results along the columns\n",
    "    synthetic_df = pd.concat(synthetic_results, axis=1)\n",
    "\n",
    "    return synthetic_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60167706-3567-4ce3-afc1-5cdfa599a6bb",
   "metadata": {},
   "source": [
    "## Create synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f09174-2657-4b81-9c99-1b72a02f761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store synthetic datasets for each coverage level\n",
    "synthetic_datasets = {}\n",
    "\n",
    "# Loop through each coverage-reduced dataset\n",
    "for cov_label, df_reduced in reduced_coverage_dfs.items():\n",
    "    print(f\"Processing synthetic dataset for coverage level: {cov_label}\")\n",
    "\n",
    "    # Generate synthetic dataset using the reduced ATAC-seq data\n",
    "    synthetic_multiplied_df = multiply_reference_with_combinations(df_reduced, syn_combo_df)\n",
    "\n",
    "    # Sum across cell type columns for each combo\n",
    "    synthetic_summed_df = synthetic_multiplied_df.groupby(level=0, axis=1).sum()\n",
    "\n",
    "    # Store the result\n",
    "    synthetic_datasets[cov_label] = synthetic_summed_df\n",
    "\n",
    "    # Print preview\n",
    "    print(f\"Preview of synthetic dataset at {cov_label} coverage:\")\n",
    "    print(synthetic_summed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c011ca7-b3e1-417d-b233-71bad74e2767",
   "metadata": {},
   "source": [
    "## Save the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85e587-844e-4599-941d-777fafdecf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = \"/mnt/DATA3/daniel/project/03_synthetic_samples/data/synthetic_coverage_reduced_0bp/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each synthetic dataset and save as CSV\n",
    "for cov_label, df_synthetic in synthetic_datasets.items():\n",
    "    file_path = os.path.join(output_dir, f\"synthetic_dataset_{cov_label}.csv\")\n",
    "    df_synthetic.to_csv(file_path, sep=\";\", index=True) \n",
    "    print(f\"Saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15d4cc-76e4-46be-90b3-4d91cbb88ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a688da3-34d7-4665-b9bd-0e13f8702743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
