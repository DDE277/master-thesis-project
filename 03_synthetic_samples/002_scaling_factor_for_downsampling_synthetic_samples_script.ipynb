{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bbea5f-0d2b-4a92-8273-c14b883cb36c",
   "metadata": {},
   "source": [
    "# Determine scaling factors for down-sampling in synthetic datasets\n",
    "- Scales the reference markers so that the minimum non-zero value equals 1\n",
    "- Computes the total summed reference marker signal\n",
    "- Computes the total fragment count per cfDNA sample and their mean\n",
    "- Estimates the expected total counts for the different coverage levels based on the cfDNA mean\n",
    "- Calculates scaling factors to simulate synthetic datasets at the desired coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6495883-51c4-432d-a57f-0d4164d0de04",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bcdfc-5b33-41c4-86e0-6c77a400c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda0c4c-7668-4401-bcf9-66aba3e1c3e2",
   "metadata": {},
   "source": [
    "## Load the cfDNA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76745b-efcd-4cda-9bd6-d3e52c6632b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory containing the files\n",
    "base_dir = \"/mnt/DATA3/daniel/project/02_cfDNA_preprocessing/data/03_intersect_mapped/cfDNA_healthy_original/\"\n",
    "\n",
    "# List of sample IDs\n",
    "sample_ids = [\"EE87922\", \"EE87925\", \"EE87927\", \"EE87932\", \"EE87933\"]\n",
    "\n",
    "# Create an empty dictionary to store DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Loop through each sample ID and load the corresponding BED file\n",
    "for sample in sample_ids:\n",
    "    file_path = f\"{base_dir}/{sample}/mapped_counts/Gfeller/{sample}_summed_marker_counts.bed\"\n",
    "    \n",
    "    # Load the BED file\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\", f\"{sample}\"])\n",
    "    \n",
    "    # Store in dictionary\n",
    "    dfs[sample] = df\n",
    "\n",
    "# Merge all DataFrames on the \"chrom\", \"start\", \"end\" columns\n",
    "df_merged = dfs[sample_ids[0]]  \n",
    "\n",
    "for sample in sample_ids[1:]:  # Merge the remaining ones\n",
    "    df_merged = df_merged.merge(dfs[sample], on=[\"chrom\", \"start\", \"end\"], how=\"outer\")\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d540936-97b6-4109-9711-15034220bfad",
   "metadata": {},
   "source": [
    "## Load the reference marker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a345d6-fe25-4290-857f-53a960667f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for synthetic dataset\n",
    "marker_file = \"/mnt/DATA3/daniel/project/03_synthetic_samples/data/reference_marker_counts.csv\"\n",
    "\n",
    "# Load synthetic dataset\n",
    "df_marker = pd.read_csv(marker_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae2d0a-56cd-4b16-b89e-f185c347b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ccbd2-630c-428e-9ff4-97da49f9c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'peak_id' column to sum only the numeric values\n",
    "df_numeric = df_marker.iloc[:, 1:]\n",
    "\n",
    "# Compute the total summed signal in the reference marker matrix\n",
    "total_reference_signal = df_numeric.sum().sum()\n",
    "\n",
    "print(f\"Total summed signal in reference marker matrix: {total_reference_signal:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4760505-323f-44d7-8e26-ba580032a9e0",
   "metadata": {},
   "source": [
    "## Scaling the reference marker matrix to replicate fragment counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a79f6-97ca-41c0-8f77-bfaf238fc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure peak_id is included\n",
    "df_scaled = df_marker.set_index(\"peak_id\")  \n",
    "\n",
    "# Find the minimum non-zero value across all regions and cell types\n",
    "min_signal = df_scaled[df_scaled > 0].min().min()\n",
    "\n",
    "# Scale reference marker matrix so that min signal = 1\n",
    "df_scaled = df_scaled / min_signal\n",
    "\n",
    "# Reset index to keep peak_id as a column\n",
    "df_scaled.reset_index(inplace=False)\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda315a-a8ab-49ed-9e0c-926083ff9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total summed signal in the scaled reference marker matrix\n",
    "total_reference_signal_scaled = df_scaled.sum().sum()\n",
    "\n",
    "print(f\"Total summed signal in scaled reference marker matrix: {total_reference_signal_scaled:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385dfb5e-0eed-460e-a7a0-ceff27660d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_scaled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097991a8-a7fc-456b-8b3c-0f3367f71e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file path\n",
    "# output_file = \"/mnt/DATA3/daniel/project/2_cfDNA_data/data/reference_marker_counts_scaled.csv\"\n",
    "\n",
    "# Save DataFrame as CSV, keeping the index\n",
    "# df_scaled.to_csv(output_file, index=True)\n",
    "\n",
    "# print(f\"Scaled reference marker matrix saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59bfd78-21f0-432c-9445-db69719e24a5",
   "metadata": {},
   "source": [
    "## cfDNA calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286014fc-3314-40b3-b03e-59f0ff989441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total summed counts for each individual sample\n",
    "sample_totals = {sample: df_merged[sample].sum() for sample in sample_ids}\n",
    "\n",
    "# Print summed counts per sample\n",
    "for sample, total in sample_totals.items():\n",
    "    print(f\"Total summed counts for {sample}: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a832e-5a0e-41d3-b4e6-d85b6d5887e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean total counts across all samples\n",
    "mean_total_signal = sum(sample_totals.values()) / len(sample_totals)\n",
    "\n",
    "print(f\"Mean summed counts across healthy cfDNA samples: {mean_total_signal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc13a3c-631e-456f-84ad-ded519902fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_region = mean_total_signal/716\n",
    "print(mean_per_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de790c3-024f-477b-ad21-f3a8a47e3b8a",
   "metadata": {},
   "source": [
    "## Determine the equivalent fragment signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ce8e0-0b8b-4863-bc6c-75c3863fe907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target coverages\n",
    "target_coverages = [0.1, 0.3, 1, 3, 9, 30, 80, 245]\n",
    "\n",
    "# Given cfDNA coverage\n",
    "cfDNA_coverage = 2.7\n",
    "\n",
    "# Compute equivalent signal\n",
    "equivalent_signal = {target: (target / cfDNA_coverage) * mean_total_signal for target in target_coverages}\n",
    "\n",
    "# Print computed equivalent signals\n",
    "print(\"Computed equivalent signal:\")\n",
    "for target, signal in sorted(equivalent_signal.items(), reverse=True):  \n",
    "    print(f\"Target coverage: {target}x, Computed equivalent signal: {signal:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353454dc-72de-4cd6-8ef8-10bb88eaf090",
   "metadata": {},
   "source": [
    "## Determine the divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649c218-c431-4dae-b947-19241d7f2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute divisors based on scaled reference marker signal\n",
    "divisors = {target: total_reference_signal_scaled / equivalent_signal[target] for target in target_coverages}\n",
    "\n",
    "# Print computed divisors\n",
    "print(\"\\nComputed divisors for synthetic sample creation:\")\n",
    "for target, divisor in sorted(divisors.items(), reverse=True):\n",
    "    print(f\"Target coverage: {target}x, Computed divisor: {divisor:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eed862-8b02-4ed3-a710-209556ebc380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c4eac-3c9d-427c-95f8-f28c8c0810e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb29d69-6b12-4cc8-9ab8-c3e1439d7680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18769c-25a0-4502-821e-6fd50dfe32b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bcf71-4dd2-43c8-85fe-56439ced92a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
