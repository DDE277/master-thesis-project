{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d1b72e-4d6c-4eba-ac2f-76af3095c128",
   "metadata": {},
   "source": [
    "# Weighted accessibility scores from Corces bigwig files in Gabriel reference matrix regions\n",
    "- Calculating weighted ATAC-seq scores per genomic region across samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf010b-c56c-4ac6-b928-1d770eb023f5",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffca6d-c522-4ee8-9d5c-f6690ee56387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c93c88-40cb-42db-be51-bb023a07321f",
   "metadata": {},
   "source": [
    "## Define directories and load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fa5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the original Gfeller regions BED file\n",
    "gfeller_bed = \"/mnt/DATA3/daniel/project/01_ATAC_preprocessing/data/original_reference_regions.bed\"\n",
    "\n",
    "# Directory containing BedGraph files\n",
    "bedgraph_dir = \"/mnt/DATA3/daniel/project/01_ATAC_preprocessing/data/corces/LUSC_merged_samples/\"\n",
    "\n",
    "# Output directory for results\n",
    "output_dir = \"/mnt/DATA3/daniel/project/01_ATAC_preprocessing/data/corces/LUSC_per_sample_scores/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check if a value is a valid float\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18918345-3ea5-4a7a-b715-4b22cd12294b",
   "metadata": {},
   "source": [
    "## Process each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_sample(sample_file, gfeller_bed, bedgraph_dir, output_dir):\n",
    "    sample_name = os.path.splitext(sample_file)[0]\n",
    "    bedgraph_path = os.path.join(bedgraph_dir, sample_file)\n",
    "\n",
    "    overlap_bed = os.path.join(output_dir, f\"{sample_name}_overlap.bed\")\n",
    "\n",
    "    # Bedtools intersect command\n",
    "    intersect_cmd = [\n",
    "        \"bedtools\", \"intersect\",\n",
    "        \"-a\", bedgraph_path,\n",
    "        \"-b\", gfeller_bed,\n",
    "        \"-wa\", \"-wb\"\n",
    "    ]\n",
    "\n",
    "    # Run bedtools intersect\n",
    "    try:\n",
    "        with open(overlap_bed, 'w') as out_bed:\n",
    "            subprocess.run(intersect_cmd, stdout=out_bed, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error intersecting {sample_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if overlap file is empty\n",
    "    if os.path.getsize(overlap_bed) == 0:\n",
    "        print(f\"No overlaps found for {sample_name}.\")\n",
    "        os.remove(overlap_bed)\n",
    "        return\n",
    "\n",
    "    # Validate lines\n",
    "    with open(overlap_bed, 'r') as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 7:\n",
    "                print(f\"Line {i} has insufficient columns: {line.strip()}\")\n",
    "                continue\n",
    "            chrom, start, end, score, gf_chrom, gf_start, gf_end = fields[:7]\n",
    "            if not (start.isdigit() and end.isdigit()):\n",
    "                print(f\"Line {i} has invalid coordinates: {line.strip()}\")\n",
    "                continue\n",
    "            if not is_float(score):\n",
    "                print(f\"Line {i} has invalid score: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "    # Read into a DataFrame\n",
    "    overlap_df = pd.read_csv(\n",
    "        overlap_bed,\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        names=['BedGraph_Chromosome', 'BedGraph_Start', 'BedGraph_End', 'BedGraph_Score',\n",
    "               'Gfeller_Chromosome', 'Gfeller_Start', 'Gfeller_End'],\n",
    "        dtype={\n",
    "            'BedGraph_Chromosome': str,\n",
    "            'BedGraph_Start': int,\n",
    "            'BedGraph_End': int,\n",
    "            'BedGraph_Score': float,\n",
    "            'Gfeller_Chromosome': str,\n",
    "            'Gfeller_Start': int,\n",
    "            'Gfeller_End': int\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compute overlap lengths and weighted scores\n",
    "    overlap_df['Overlap_Start'] = overlap_df[['BedGraph_Start', 'Gfeller_Start']].max(axis=1)\n",
    "    overlap_df['Overlap_End'] = overlap_df[['BedGraph_End', 'Gfeller_End']].min(axis=1)\n",
    "    overlap_df['Overlap_Length'] = overlap_df['Overlap_End'] - overlap_df['Overlap_Start']\n",
    "    overlap_df = overlap_df[overlap_df['Overlap_Length'] > 0]\n",
    "    overlap_df['Weighted_Score'] = overlap_df['BedGraph_Score'] * overlap_df['Overlap_Length']\n",
    "\n",
    "    # Aggregate per region\n",
    "    grouped = overlap_df.groupby(['Gfeller_Chromosome', 'Gfeller_Start', 'Gfeller_End']).agg(\n",
    "        total_weighted_score=('Weighted_Score', 'sum'),\n",
    "        total_overlap_length=('Overlap_Length', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute weighted average per region\n",
    "    grouped['Weighted_Average_Score'] = grouped['total_weighted_score'] / grouped['total_overlap_length']\n",
    "    grouped['Weighted_Average_Score'] = grouped['Weighted_Average_Score'].round(4)\n",
    "\n",
    "    # Select relevant columns\n",
    "    final_df = grouped[['Gfeller_Chromosome', 'Gfeller_Start', 'Gfeller_End', 'Weighted_Average_Score']]\n",
    "    final_df.columns = ['Chromosome', 'Start', 'End', 'Weighted_Average_Score']\n",
    "\n",
    "    # Save results for this sample\n",
    "    sample_output_csv = os.path.join(output_dir, f\"{sample_name}_weighted_scores.csv\")\n",
    "    final_df.to_csv(sample_output_csv, index=False)\n",
    "    print(f\"Saved per-region weighted average scores for {sample_name} to {sample_output_csv}\")\n",
    "\n",
    "    # Clean up intermediate file\n",
    "    os.remove(overlap_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all BedGraph files in the directory\n",
    "bedgraph_files = [f for f in os.listdir(bedgraph_dir) if f.endswith('.bedGraph')]\n",
    "\n",
    "# Filter for BRCA samples (assuming filenames start with BRCA)\n",
    "brca_files = [f for f in bedgraph_files if f.startswith('LUSC')]\n",
    "brca_files = brca_files[:10]  # Take the first 10 BRCA samples\n",
    "\n",
    "print(f\"Processing {len(brca_files)} BRCA samples...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_file in brca_files:\n",
    "    process_single_sample(\n",
    "        sample_file=sample_file,\n",
    "        gfeller_bed=gfeller_bed,\n",
    "        bedgraph_dir=bedgraph_dir,\n",
    "        output_dir=output_dir\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
