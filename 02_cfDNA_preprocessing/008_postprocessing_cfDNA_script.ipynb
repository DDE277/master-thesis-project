{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36805140-c487-4af2-9190-77a04815631b",
   "metadata": {},
   "source": [
    "# Post-processing for cfDNA fragment center counts\n",
    "- Trimming to 100 bp\n",
    "- row-wise averaging within the trimmed data\n",
    "- Re-assignment to the marker regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a217bb-d215-4d4e-ac48-bb8423f25a1b",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e61c07-435a-42ee-80b4-24d4d67a81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fa0a1-8d4d-4682-88ed-17e3b2b4490b",
   "metadata": {},
   "source": [
    "## Load smoothed cfDNA data from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873385b-1951-47f9-84fd-f795ffc082b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load smoothed cfDNA data\n",
    "def load_smoothed_data(base_directory):\n",
    "    df_dict = {}\n",
    "    for sample_id in os.listdir(base_directory):\n",
    "        sample_path = os.path.join(base_directory, sample_id, f\"{sample_id}_smoothed.pkl\")\n",
    "        if os.path.exists(sample_path):\n",
    "            df_dict[sample_id] = pd.read_pickle(sample_path)\n",
    "            print(f\"Loaded: {sample_id}, Shape: {df_dict[sample_id].shape}\")\n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ca835-e9a2-4d01-a73a-6101d287749c",
   "metadata": {},
   "source": [
    "## Trim each cfDNA sample to the central 100 bp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b59f4-f049-452f-985b-51fff9908b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim cfDNA to 100 bp\n",
    "def trim_cfDNA(df_dict, start=950, end=1050):\n",
    "    df_trimmed_dict = {}\n",
    "    for sample_id, df in df_dict.items():\n",
    "        trimmed_df = df.iloc[:, start:end].copy()\n",
    "        trimmed_df.columns = range(trimmed_df.shape[1])\n",
    "        df_trimmed_dict[sample_id] = trimmed_df\n",
    "    return df_trimmed_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffa52e-1eff-4162-b8ac-ff161bdb0a52",
   "metadata": {},
   "source": [
    "## Compute row-wise mean fragment center signal for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4cc03-8f7f-4bf7-a820-fe542ac63167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate row-wise mean for trimmed cfDNA data\n",
    "def calculate_row_means(df_trimmed_dict):\n",
    "    row_means_dict = {sample_id: df.mean(axis=1) for sample_id, df in df_trimmed_dict.items()}\n",
    "    return row_means_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80707def-6172-4b3f-aa34-520950ddf950",
   "metadata": {},
   "source": [
    "## Load marker regions from BED file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf9896-68ca-4eba-813a-e3ae0a8d6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load marker regions\n",
    "def load_marker_regions(marker_file_path):\n",
    "    df_markers = pd.read_csv(marker_file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\"])\n",
    "    df_markers[\"chrom\"] = df_markers[\"chrom\"].astype(str).str.strip()\n",
    "    df_markers[\"start\"] = df_markers[\"start\"].astype(int)\n",
    "    df_markers[\"end\"] = df_markers[\"end\"].astype(int)\n",
    "    print(f\"Loaded {len(df_markers)} marker regions.\")\n",
    "    return df_markers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade0fc5-42d2-4aa1-8fd1-fb73a27629ec",
   "metadata": {},
   "source": [
    "## Assign mean cfDNA signals to corresponding marker regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb30cc5-0f7c-463c-b16c-6d2e0a07212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cfDNA data to original marker regions\n",
    "def assign_original_regions(df_markers, row_means_dict):\n",
    "    df_combined = df_markers.copy()\n",
    "    for sample_id, row_means in row_means_dict.items():\n",
    "        df_combined[sample_id] = row_means.values\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c257a01-a241-473e-b90f-51fe91295369",
   "metadata": {},
   "source": [
    "## Scale signal values per region to 0,1 after inverting signal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c5c54-c535-40c8-a8c2-79951c1cd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and scale data\n",
    "def transform_data(df_combined):\n",
    "    metadata_cols = [\"chrom\", \"start\", \"end\"]\n",
    "    sample_cols = [col for col in df_combined.columns if col not in metadata_cols]\n",
    "\n",
    "    df_combined[sample_cols] = df_combined[sample_cols] * -1\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_combined[sample_cols] = scaler.fit_transform(df_combined[sample_cols])\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c56085-4d99-4323-ac4a-eb3984345a0f",
   "metadata": {},
   "source": [
    "## Add marker start/end coordinates to the final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338eaa91-a273-4bd1-9cd6-44ee8b67a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign original marker regions directly\n",
    "def assign_marker_regions(df_combined, marker_file_path):\n",
    "    df_markers = pd.read_csv(marker_file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"marker_start\", \"marker_end\"])\n",
    "\n",
    "    if df_combined.shape[0] != df_markers.shape[0]:\n",
    "        raise ValueError(f\"Mismatch: df_combined has {df_combined.shape[0]} rows, but df_markers has {df_markers.shape[0]} rows.\")\n",
    "\n",
    "    df_combined[\"marker_start\"] = df_markers[\"marker_start\"].values\n",
    "    df_combined[\"marker_end\"] = df_markers[\"marker_end\"].values\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec694e-7d91-4314-8057-9f5c0f2939f7",
   "metadata": {},
   "source": [
    "## Save the final transformed DataFrame to a BED file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26531343-e8e5-4be7-9098-076ca380aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final transformed data\n",
    "def save_combined_data(df_combined, output_bed_file):\n",
    "    df_combined.to_csv(output_bed_file, sep=\"\\t\", header=True, index=False)\n",
    "    print(f\"Saved transformed df to: {output_bed_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271311e6-85eb-47e7-8eae-5e222391b97b",
   "metadata": {},
   "source": [
    "## Main function for post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d392e-4f8f-4c5e-80c3-522a0b28d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    base_directory = \"/mnt/DATA3/daniel/project/02_cfDNA_preprocessing/data/03_intersect_mapped/cfDNA_healthy_new/\"\n",
    "        \n",
    "    marker_file_path = \"/mnt/DATA3/daniel/project/04_DA_and_reference_building/data/new_pairwise_cell_types_markers.bed\"\n",
    "    \n",
    "    output_bed_file = os.path.join(base_directory, \"cfDNA_healthy_samples_new.bed\")\n",
    "\n",
    "    df_dict = load_smoothed_data(base_directory)\n",
    "    df_trimmed_dict = trim_cfDNA(df_dict)\n",
    "    row_means_dict = calculate_row_means(df_trimmed_dict)\n",
    "\n",
    "    df_markers = load_marker_regions(marker_file_path)\n",
    "    df_combined = assign_original_regions(df_markers, row_means_dict)\n",
    "\n",
    "    df_scaled = transform_data(df_combined)\n",
    "    df_final = assign_marker_regions(df_scaled, marker_file_path)\n",
    "\n",
    "    save_combined_data(df_final, output_bed_file)\n",
    "\n",
    "    print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda72929-fdb2-4da4-a11d-9bb365022a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001fdc3-203c-4043-95be-070de640eabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
