{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d4e7f9-5186-42be-97c5-9ccd7ae9f800",
   "metadata": {},
   "source": [
    "# Visualization of cfDNA fragment center profiles across universal open/closed and cell-type specific regions\n",
    "- Loads smoothed cfDNA fragment count matrices (z-score normalized) for selected samples\n",
    "- Loads cell-type-specific marker regions, universal open regions, and universal closed regions.\n",
    "- Extracts matching regions from cfDNA data for universal open and closed regions.\n",
    "- Merges original genomic regions with smoothed cfDNA profiles for all samples.\n",
    "- Filters merged data to keep only cell-type marker regions.\n",
    "- Computes average fragment profiles per cell type and sample.\n",
    "- Combines and aggregates profiles across samples for each cell type.\n",
    "- Computes mean Â± standard deviation for universal open, closed, and cell-type-specific regions.\n",
    "- Generates subplots visualizing cfDNA fragment patterns across cell types and open/closed states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ab061-8cc9-488c-a74a-e9040042c114",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bc3c4-48c9-47ca-86b4-8d474396d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5abe3-9431-4abc-ac44-2a4fce985ee2",
   "metadata": {},
   "source": [
    "## Import pickle cfDNA smoothed z-score normalized counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143fbfe-7bdb-4e14-843f-e5494867254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory\n",
    "base_directory = \"/mnt/DATA3/daniel/project/02_cfDNA_preprocessing/data/03_intersect_mapped/cfDNA_healthy_original/\"\n",
    "\n",
    "# Define the specific sample IDs \n",
    "sample_ids = [\"EE87922\", \"EE87925\", \"EE87927\", \"EE87932\", \"EE87933\"]\n",
    "\n",
    "# Load each pickle file following the naming convention\n",
    "df_dict = {}\n",
    "for sample_id in sample_ids:\n",
    "    file_path = os.path.join(base_directory, sample_id, f\"{sample_id}_smoothed_sub.pkl\")\n",
    "    if os.path.exists(file_path):  \n",
    "        df_dict[sample_id] = pd.read_pickle(file_path)\n",
    "        print(f\"Loaded: {sample_id}, Shape: {df_dict[sample_id].shape}\")  \n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36219008-b51c-495c-8708-f9ba8d418140",
   "metadata": {},
   "source": [
    "# Import cell type marker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b3ea0-3e20-48ad-8bad-34b97ba53581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your pickle file\n",
    "cell_type_markers = '/mnt/DATA3/daniel/project/01_ATAC_preprocessing/data/subset_trimmed_data_markers/all_cell_types_markers.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_markers = pd.read_csv(cell_type_markers)\n",
    "print(df_markers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc14023-b44c-4ee3-903c-99c2252df867",
   "metadata": {},
   "source": [
    "# Import universal closed and open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f492e-a736-42bd-b740-abb695968ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample IDs\n",
    "sample_ids = [\"EE87922\", \"EE87925\", \"EE87927\", \"EE87932\", \"EE87933\"]\n",
    "\n",
    "# Create an empty dictionary to store DataFrames\n",
    "df_universal_closed_dict = {}\n",
    "\n",
    "# Loop through each sample and load its smoothed universal closed counts\n",
    "for sample_id in sample_ids:\n",
    "    file_path = os.path.join(base_directory, sample_id, f\"{sample_id}_universal_closed_smoothed.pkl\")\n",
    "    \n",
    "    if os.path.exists(file_path):  \n",
    "        df_universal_closed_dict[sample_id] = pd.read_pickle(file_path)\n",
    "        print(f\"Loaded: {sample_id}, Shape: {df_universal_closed_dict[sample_id].shape}\")  \n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de25a5-9843-4193-806f-f325140e8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display one of the merged DataFrames\n",
    "print(df_universal_closed_dict[\"EE87922\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fa952-98e0-4e2f-a29a-7f2f8129304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the universal open region file\n",
    "universal_open_file = \"/mnt/DATA3/daniel/project/02_cfDNA_preprocessing/data/02_split_chromosomes/universal_open_regions/trimmed_universal_accessible_regions.bed\"\n",
    "\n",
    "df_universal_open = pd.read_csv(universal_open_file, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\"])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_universal_open.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a294e-b842-4438-9de5-01a1b980ba45",
   "metadata": {},
   "source": [
    "# Import the original region file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8c77d-1674-45ae-beb2-2975766a1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original region file\n",
    "original_regions_file = \"/mnt/DATA3/daniel/project/01_ATAC_preprocessing/data/original_reference_regions_sorted.bed\"\n",
    "\n",
    "df_original = pd.read_csv(original_regions_file, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\"])\n",
    "\n",
    "print(df_original.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab61140-ed6a-4982-9a1f-5f675bbfa0f2",
   "metadata": {},
   "source": [
    "# Extract universal open regions from cfDNA smoothed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae561e-8b91-4703-8d15-28d2894b07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store extracted universal open regions from cfDNA smoothed files\n",
    "df_open_extracted_dict = {}\n",
    "\n",
    "# Loop through each sample and extract the universal open regions\n",
    "for sample_id in sample_ids:\n",
    "    file_path = os.path.join(base_directory, sample_id, f\"{sample_id}_smoothed_sub.pkl\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        df_smoothed = pd.read_pickle(file_path)\n",
    "        \n",
    "        # Extract chrom, start, and end from index\n",
    "        df_smoothed = df_smoothed.reset_index()\n",
    "        df_smoothed[['chrom', 'coords']] = df_smoothed['index'].astype(str).str.split(':', expand=True)\n",
    "        df_smoothed[['start', 'end']] = df_smoothed['coords'].str.split('-', expand=True)\n",
    "        df_smoothed[['start', 'end']] = df_smoothed[['start', 'end']].astype(int)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        df_smoothed = df_smoothed.drop(columns=['index', 'coords'])\n",
    "\n",
    "        # Extract only universal open regions\n",
    "        df_open_extracted = df_smoothed.merge(df_universal_open, on=['chrom', 'start', 'end'], how='inner')\n",
    "        \n",
    "        # Store in dictionary\n",
    "        df_open_extracted_dict[sample_id] = df_open_extracted\n",
    "        print(f\"Extracted {df_open_extracted.shape[0]} universal open regions for {sample_id}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf60e4-2ea6-4496-b378-6e53cf23f893",
   "metadata": {},
   "source": [
    "# Assign original regions to the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b63dd-40fe-415f-9cff-fafcd553f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store merged DataFrames for each sample\n",
    "df_merged_dict = {}\n",
    "\n",
    "# Loop through each sample and merge with original regions\n",
    "for sample_id in sample_ids:\n",
    "    if sample_id in df_dict: \n",
    "        df_smoothed_sub = df_dict[sample_id]  \n",
    "\n",
    "        # Make a copy of df_original\n",
    "        df_merged = df_original.copy()\n",
    "\n",
    "        # Append the values from df_smoothed_sub\n",
    "        df_merged = pd.concat([df_merged, df_smoothed_sub.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Store merged DataFrame in dictionary\n",
    "        df_merged_dict[sample_id] = df_merged\n",
    "        \n",
    "        print(f\"Merged {sample_id}: {df_merged.shape}\")\n",
    "\n",
    "# Display one of the merged DataFrames\n",
    "print(df_merged_dict[\"EE87922\"].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c0088-7a16-47d8-843c-5227dba00596",
   "metadata": {},
   "source": [
    "# Extract the cell type marker regions from the smoothed cfDNA samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6c5ce-18cb-4852-800b-23a1bd5e4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure start and end are integers in df_markers\n",
    "df_markers[['start', 'end']] = df_markers[['start', 'end']].astype(int)\n",
    "\n",
    "# Dictionary to store the filtered DataFrames for each sample\n",
    "df_filtered_markers_dict = {}\n",
    "\n",
    "# Loop through each sample and extract marker-associated regions\n",
    "for sample_id, df_merged in df_merged_dict.items():\n",
    "    \n",
    "    # Ensure start and end are integers in df_merged\n",
    "    df_merged[['start', 'end']] = df_merged[['start', 'end']].astype(int)\n",
    "\n",
    "    # Extract only the rows from df_merged that match df_markers regions\n",
    "    df_filtered_markers = df_merged.merge(df_markers, on=['chrom', 'start', 'end'], how='inner')\n",
    "\n",
    "    # Store filtered DataFrame in dictionary\n",
    "    df_filtered_markers_dict[sample_id] = df_filtered_markers\n",
    "    \n",
    "    print(f\"Filtered markers for {sample_id}: {df_filtered_markers.shape}\")\n",
    "\n",
    "# Display the first few rows of a filtered sample\n",
    "print(df_filtered_markers_dict[\"EE87922\"].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ae481-8d44-42fc-85db-a57b898e4001",
   "metadata": {},
   "source": [
    "# Compute the mean and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffaa53-fef1-4214-b860-49c6df979576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store sample-wise (marker-based) means\n",
    "df_mean_per_sample_dict = {}  # store (2000 x cell_types) per sample\n",
    "\n",
    "for sample_id, df_filtered_markers in df_filtered_markers_dict.items():\n",
    "    # 1. Group by cell_type, average -> shape(#cell_types, 2000)\n",
    "    df_mean_per_cell = df_filtered_markers.groupby('cell_type').mean(numeric_only=True)\n",
    "    # 2. Transpose -> shape(2000, #cell_types)\n",
    "    df_mean_per_cell = df_mean_per_cell.T\n",
    "    \n",
    "    df_mean_per_sample_dict[sample_id] = df_mean_per_cell\n",
    "\n",
    "# Stack all samples row-wise -> shape(2000*S, #cell_types)\n",
    "df_combined_means = pd.concat(df_mean_per_sample_dict.values(), axis=0)\n",
    "\n",
    "# Mean across samples (group by row index -> 2000 bins)\n",
    "df_mean_across_samples = df_combined_means.groupby(df_combined_means.index).mean()\n",
    "# Std across samples\n",
    "df_std_across_samples  = df_combined_means.groupby(df_combined_means.index).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cc693-d54a-4baf-a14d-eaf83c265115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store universal-open mean per sample\n",
    "df_universal_open_mean_dict = {}\n",
    "\n",
    "for sample_id, df_open_extracted in df_open_extracted_dict.items():\n",
    "    numeric_cols = df_open_extracted.select_dtypes(include=[np.number]).columns\n",
    "    mean_profile = df_open_extracted[numeric_cols].mean(axis=0)\n",
    "    df_universal_open_mean_dict[sample_id] = mean_profile\n",
    "\n",
    "df_universal_open_combined = pd.DataFrame(df_universal_open_mean_dict)\n",
    "universal_open_mean = df_universal_open_combined.mean(axis=1)  \n",
    "universal_open_std  = df_universal_open_combined.std(axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6d0a2-0272-453a-ada4-0a7549dbcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for universal-closed mean per sample\n",
    "df_universal_closed_mean_dict = {}\n",
    "\n",
    "for sample_id, df_closed in df_universal_closed_dict.items():\n",
    "    numeric_cols = df_closed.select_dtypes(include=[np.number]).columns\n",
    "    mean_profile = df_closed[numeric_cols].mean(axis=0)\n",
    "    df_universal_closed_mean_dict[sample_id] = mean_profile\n",
    "\n",
    "df_universal_closed_combined = pd.DataFrame(df_universal_closed_mean_dict)\n",
    "universal_closed_mean = df_universal_closed_combined.mean(axis=1)\n",
    "universal_closed_std  = df_universal_closed_combined.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58976d-48af-414e-91f2-4ac711355347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_across_samples[\"Universal_Open\"] = universal_open_mean\n",
    "df_mean_across_samples[\"Universal_Closed\"] = universal_closed_mean\n",
    "\n",
    "df_std_across_samples[\"Universal_Open\"] = universal_open_std\n",
    "df_std_across_samples[\"Universal_Closed\"] = universal_closed_std\n",
    "\n",
    "# Convert index to numeric (so we can do linspace, etc.)\n",
    "df_mean_across_samples.index = pd.to_numeric(df_mean_across_samples.index, errors='coerce')\n",
    "df_std_across_samples.index  = pd.to_numeric(df_std_across_samples.index, errors='coerce')\n",
    "\n",
    "# Drop any NaNs in the index\n",
    "df_mean_across_samples = df_mean_across_samples[~df_mean_across_samples.index.isna()]\n",
    "df_std_across_samples  = df_std_across_samples[~df_std_across_samples.index.isna()]\n",
    "\n",
    "# Sort the index if needed\n",
    "df_mean_across_samples = df_mean_across_samples.sort_index()\n",
    "df_std_across_samples  = df_std_across_samples.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b405633-2870-4a73-be76-eda1b23f61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\"Universal_Open\", \"Universal_Closed\"] + [\n",
    "    col for col in df_mean_across_samples.columns\n",
    "    if col not in [\"Universal_Open\", \"Universal_Closed\"]\n",
    "]\n",
    "\n",
    "df_reordered_mean = df_mean_across_samples[col_order]\n",
    "df_reordered_std  = df_std_across_samples[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65c828-824b-4849-950d-7f01bb47b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = df_reordered_mean.columns\n",
    "n_plots = len(df_cols)\n",
    "ncols = 3\n",
    "nrows = 4 \n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(18, 5*nrows), sharex=False, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define custom x-range\n",
    "original_ticks = np.linspace(df_reordered_mean.index.min(),\n",
    "                             df_reordered_mean.index.max(),\n",
    "                             num=5)\n",
    "new_tick_labels = np.linspace(-1000, 1000, num=5)\n",
    "\n",
    "for i, column_name in enumerate(df_cols):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    ax = axes[i]\n",
    "    ax.set_title(column_name, fontsize=16)\n",
    "\n",
    "    mean_values = df_reordered_mean[column_name]\n",
    "    std_values  = df_reordered_std[column_name]\n",
    "\n",
    "    # Plot the mean line\n",
    "    ax.plot(df_reordered_mean.index, mean_values, label=column_name, color=\"blue\")\n",
    "    \n",
    "    # Shaded area: mean Â± 1 std\n",
    "    ax.fill_between(\n",
    "        df_reordered_mean.index,\n",
    "        mean_values - std_values,\n",
    "        mean_values + std_values,\n",
    "        alpha=0.2, color=\"blue\", label=\"Â±1 SD\"\n",
    "    )\n",
    "    \n",
    "    # Set x-ticks\n",
    "    ax.set_xticks(original_ticks)\n",
    "    ax.set_xticklabels([f\"{int(x)}\" for x in new_tick_labels])\n",
    "    # Increase the tick label font size on both axes to 16\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "    \n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "for j in range(i+1, nrows*ncols):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "# Add a figure-level title \n",
    "fig.suptitle(\"Smoothed z-score normalized cfDNA fragment center count profiles\", fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "# Adjust layout \n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "\n",
    "# Save the figure \n",
    "plt.savefig(\"smoothed_zscore_cfDNA_profiles.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310db165-1e0a-4579-888a-0199a19eb5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f90a54-eaa4-4b19-965d-7e76adb7f4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597fc9b-4afb-47e6-95b9-e8401b8b6a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
